{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Predicción de Abandono\n",
        "format: pdf\n",
        "editor: visual\n",
        "execute:\n",
        "  echo: true\n",
        "  warning: false\n",
        "---"
      ],
      "id": "1aadcede"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Contexto\n",
        "\n",
        "Cell2Cell es una compañía de teléfonos celulares que intenta mitigar el abandono de sus usuarios. Te contratan para 1) Encontrar un modelo que prediga el abandono con acierto y para usar los insights de este modelo para proponer una estrategia de manejo de abandono.\n",
        "\n",
        "Las preguntas que contestaremos son:\n",
        "\n",
        "1\\. Se puede predecir el abandono con los datos que nos compartieron?\n",
        "\n",
        "2\\. Cuáles son las variables que explican en mayor medida el abandono?\n",
        "\n",
        "3\\. Qué incentivos da Cell2Cell a sus usarios para prevenir el abandono?\n",
        "\n",
        "4\\. Cuál es el valor de una estrategia de prevención de abandono focalizada y cómo difiere entre los segmentos de los usuarios? Qué usuarios deberían de recibir incentivos de prevención? Qué montos de incentivos\n",
        "\n",
        "Nota: Voy a evaluar las tareas con base en la respuesta a cada pregunta. Como hay algunas preguntas que no tienen una respuesta clara, al final ponderaré de acuerdo al poder predictivo de su modelo vs las respuestas sugeridas.\n",
        "\n",
        "\\newpage\n",
        "\n",
        "## Datos\n",
        "\n",
        "Los dotos los pueden encontrar en \\`Cell2Cell.csv\\`. En el archivo \\`Cell2Cell-Database-Documentation.xlsx\\` pueden encontrar documentación de la base de datos.\n"
      ],
      "id": "22be83a2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "import pandas as pd \n",
        "import math \n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "!pip install polars\n",
        "import polars as pl\n",
        "from plotnine import ggplot, aes, geom_point, geom_line, geom_col, geom_histogram, geom_smooth , geom_bar, geom_boxplot, labs, coord_flip, facet_wrap, theme_bw"
      ],
      "id": "54f6ae7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Qué variables tienen missing values? Toma alguna decisión con los missing values. Justifica tu respuesta\n"
      ],
      "id": "5e69df33"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Leyendo la base de datos\n",
        "data = pd.read_csv('Bases input/cell2cell.csv')\n",
        "\n",
        "# Que me muestre todo\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "\n",
        "# how many missings per variable\n",
        "missings = data.isna().mean()*100\n",
        "missings = missings[missings>0]\n",
        "missings.sort_values(ascending= False)"
      ],
      "id": "5fd03474",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "eqpdays, phones, models, los voy a quitar dando que son menos del 0.001% de las observaciones\n",
        "\n",
        "El resto las reemplazo por ceros.\n"
      ],
      "id": "9855edc4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Quitando las que tienen pocas observaciones \n",
        "data = data[~pd.isnull(data.age1)]\n",
        "data = data[~pd.isnull(data.age2)]\n",
        "data = data[~pd.isna(data.eqpdays)]\n",
        "\n",
        "\n",
        "# El resto las lleno con zero\n",
        "data = data.fillna(0)\n",
        "np.shape(data)\n"
      ],
      "id": "394bcd52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Tabula la distribución de la variable `churn`. Muestra la frecuencia absoluta y relativa. Crees que se debe hacer oversampling/undersamping?\n",
        "\n",
        "Tiene una distribución 70%/30%. Parece que si habrá que hacer algo de sampling.\n"
      ],
      "id": "dbacf8a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "tab = 100*data.churn.value_counts()/data.shape[0]\n",
        "%matplotlib inline\n",
        "ggplot(data)+geom_bar(aes(x = 'churn'))+theme_bw()"
      ],
      "id": "a9a10996",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. (2 pts) Divide tu base en entrenamiento y validación (80/20).\n",
        "\n",
        "Además, considera hacer oversampling (SMOTE) o undersampling.\n",
        "\n",
        "(Tip: Recuerda que el objetivo final es tener muestra \\~balanceada en el traning set. En el validation la distribución debe ser la original).\n",
        "\n",
        "La distribución esta 70% vs 30%. Si queremos construir un training set = 80%. Dentro del training, hay que hacer el undersampling tal que se balanceen las clases.\n"
      ],
      "id": "c9dd8567"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Pandas way\n",
        "data_train = data.sample(frac = 0.8, random_state = 1990)\n",
        "data_test = data.drop(data_train.index)"
      ],
      "id": "f3fd10ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Definiendo una funcion\n",
        "def n_distinct(x): \n",
        "    a = np.shape(np.unique(x))\n",
        "    return a[0]\n",
        "  \n",
        "n_distinct(data.customer)"
      ],
      "id": "34e15dcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Undersampling\n"
      ],
      "id": "4e745849"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Filtro la base donde churn == 1 \n",
        "data_train_1 = data_train[data_train.churn ==1]\n",
        "data_train_0 = data_train[data_train.churn == 0]\n",
        "\n",
        "# Undersampling\n",
        "data_train_0 = data_train_0.sample(frac = 0.41, random_state = 1990)\n",
        "\n",
        "# Base train final \n",
        "data_train = pd.concat([data_train_1, data_train_0])\n",
        "\n",
        "# Removing aux tables \n",
        "del data_train_0, data_train_1"
      ],
      "id": "b8bbd0b7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Estimation\n",
        "\n",
        "Pondremos a competir 3 modelos:\n",
        "\n",
        "1\\. Cross-Validated LASSO-logit\n",
        "\n",
        "2\\. Prune Trees\n",
        "\n",
        "3\\. Random Forest\n",
        "\n",
        "4\\. Gradient Boosting Machine\n",
        "\n",
        "### 4 (2 pts). Estima un cross validated LASSO. Muestra el la gráfica de CV Binomial Deviance vs Complejidad\n"
      ],
      "id": "458dfa7f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import  LassoLarsIC #Normal Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html\n",
        "\n",
        "# X\n",
        "X = data_train.drop(columns = ['customer', 'churn'])\n",
        "y = data_train.churn\n",
        "\n",
        "# Estandarizando la matrix \n",
        "X_std = StandardScaler().fit(X).transform(X)\n",
        "\n",
        "\n",
        "# Lasso Path Logistic Regression: Sklearn\n",
        "lasso_churn = LogisticRegression(penalty = 'l1', solver = 'liblinear')\n",
        "lasso_churn = lasso_churn.fit(X_std,y)\n",
        "\n",
        "# Lasso Path with statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/"
      ],
      "id": "31c0b39e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
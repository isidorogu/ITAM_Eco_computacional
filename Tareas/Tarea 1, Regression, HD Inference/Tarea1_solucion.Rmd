---
title: "Economía Computacional: Tarea 1"
author: "Isidoro Garcia"

date: "2021"
fontsize: 10 pt
output: 
    pdf_document:
        fig_width: 6
        fig_height: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	fig.height = 4,
	fig.width = 6,
	message = FALSE,
	warning = FALSE,
	cache = TRUE,
	digits = 3,
	width = 48
)
 
```

```{r liberias }
library(tidyverse)
library(data.table)
library(RCT)
library(knitr)
library(lfe)
library(broom)
```

En esta tarea pondrán en práctica los conceptos de High Dimensional Inference y Regresión. La base de datos muestra las compras de helados Ben & Jerry. Cada fila es una compra. Cada columna es una característica del helado comprado o de la persona que compró. 


## Limpieza de datos

Carga los datos en BenAndJerry.csv. 

```{r }
# Carga la base de datos
list.files(pattern = '.csv')
base<-fread('Bases input/BenAndJerry.csv')
```


### 1. Cuales son las columnas de la base? Muestra una tabla con ellas
```{r sol1, results='asis'}

kable(names(base))

```

### 2. A qué nivel está la base? Esto es, cuál es la variable que define la base de manera única. Si no la hay, crea una y muestra que es única a nivel de la base (Muestra el código)

```{r sol2}
nrow(base) # Obs en la base 



# unicas por variable 
(unicas<-map_dbl(base %>% select_all(), ~n_distinct(.)))

# Creando el primary key
base <-
  base %>% 
  mutate(primary_key = row_number())

```

### 3. Que variables tienen valores vacíos? Haz una tabla con el porcentaje de vacíos para las columnas que tengan al menos una observación vacía

```{r sol3, echo=TRUE}
var_na<-map_dbl(base %>% select_all(), 
              ~100*sum(is.na(.))/nrow(base))

var_na<-var_na[var_na>0]

kable(var_na)

```

### 4. Haz algo con los valores vacíos (Se deben reemplazar por algún valor? Eliminar de la base?). Justifica tu respuesta. 

- Promotion type po no promotion porque parece obvio que el vacío significa no promoción. 

- En female occupation y market identifier no es una respuesta obvia. Dado que ademas su nivel de NA's son muchos para filtrar, se pueden hacer dos cosas: 1) Declarar explícitamente los NA's como 'Other' o 2) Quitar las columnas. 

- Finalmente, para el codigo del county y para el número de televisiones, las respuestas tampoco son obvias. Dado que son menos del 1 por ciento de la base, las filtro.  


```{r sol4, }
# promotion_type 
table(base$promotion_type, useNA = 'ifany')

# Reemplazando por 'no promoción'
base<-
  base %>% 
  mutate(promotion_type = replace_na(promotion_type, replace = 'no promotion'))

table(base$promotion_type, useNA = 'ifany')

# female_head_education
table(base$female_head_occupation, useNA = 'ifany')
# scan market identifier
table(base$scantrack_market_identifier, useNA = 'ifany')


# Reemplazando por 'other' en la female_head_occupation y market identifier
base <-
  base %>% 
  mutate(female_head_occupation = replace_na(female_head_occupation, replace = 'Other'),
         scantrack_market_identifier = replace_na(scantrack_market_identifier, replace = 'Other'))

table(base$female_head_occupation, useNA = 'ifany')
table(base$scantrack_market_identifier, useNA = 'ifany')

# Census county code y tv_items: eliminar esas filas
table(base$tv_items, useNA = 'ifany')
base<-
  base %>% 
  filter(!is.na(tv_items))


var_na<-map_dbl(base %>% select_all(), 
              ~100*sum(is.na(.))/nrow(base))

var_na<-var_na[var_na>0]

  
```

### 5. Muestra una tabla de estadisticas descriptivas de la base. Esta debe tener cada columna númerica con algunas estadísticas descriptivas (N, media, min, p05, p25, p50, p75, p90, p95, max). 

```{r sol5, results='asis'}
est_desc<-summary_statistics(base)
kable(est_desc, digits = 2)

```


### 6. Hay alguna númerica que en verdad represente una categorica? Cuales? Cambialas a factor

Las variables númericas que en verdad son factores son: 

- marital_status

- male_head_occupation

- age_and_presence_of_children

- female/male_head_employment

- male/female_head_education

- household_composition

- race 

- hispanic

- region

- fips_state_code

- fips_county_code

- type_of_residence

- household_internet_connection


```{r sol6, results='asis'}
base<-
  base %>% 
  mutate(marital_status = factor(marital_status, levels = 1:4), 
         male_head_occupation = factor(male_head_occupation, levels = 1:12), 
         age_and_presence_of_children = factor(age_and_presence_of_children, levels = 1:9),
         male_head_employment = factor(male_head_employment, levels = 0:9), 
         female_head_employment = factor(female_head_employment, levels = 0:9), 
         household_composition = factor(household_composition, levels = 1:8),
         race = factor(race, levels = 1:4), 
         hispanic_origin = hispanic_origin -1, 
         region = factor(region, levels = 1:4), 
         fips_state_code = factor(fips_state_code, levels = 1:56), 
         fips_county_code = factor(fips_county_code, levels = 1:810), 
         type_of_residence = factor(type_of_residence, levels = 1:7), 
         household_internet_connection = household_internet_connection -1)


```


### 7. Revisa la distribución de algunas variables. Todas tienen sentido? Por ejemplo, las edades? 

```{r sol7}
base<-
  base %>% 
  mutate(age_of_female_head = if_else(age_of_female_head<16, 16, as.double(age_of_female_head)), 
         age_of_male_head = if_else(age_of_male_head<16, 16, as.double(age_of_male_head)))

```

### 8. Finalmente, crea una variable que sea el precio total pagado y el precio unitario

```{r sol8 }
base<-
  base %>% 
  mutate(price = price_paid_deal + price_paid_non_deal, 
         price_unit = price / quantity)

```

## Exploración de los datos 

Intentaremos comprender la elasticidad precio de los helados. Para ello, debemos entender: 

- La forma funcional base de la demanda (i.e. como se parecen relacionarse $q$ y $p$). 

- Qué variables irían en el modelo de demanda y cuáles no para encontrar la elasticidad de manera 'insesgada'. 

- Qué variables cambian la relacion de $q$ y $p$. Esto es, que variables alteran la elasticidad.

Algo importante es que siempre debemos mirar primero las variables más relevantes de cerca y su relación en: 

- Relación univariada

- Relaciones bivariadas

- Relaciones trivariadas

Importante: Las gráficas deben estar bien documentadas (título, ejes con etiquetas apropiadas, etc). Cualquier gráfica que no cumpla con estos requisitos les quitaré algunos puntos.

### 9. Cómo se ve la distribución del precio unitario y de la cantidad demandada. Haz un histograma.

```{r sol9}
ggplot(base, aes(price_unit))+
  geom_histogram(fill = 'lightsteelblue', color = 'darkgrey', bins = 80)+
  theme_bw()+
  labs(title = 'Distribución del Precio de Helados Ben & Jerry', 
       subtitle = 'USD',
       x = 'Precio (USD)')

ggplot(base, aes(quantity))+
  geom_histogram(fill = 'lightsteelblue', color = 'darkgrey', bins = 40)+
  theme_bw()+
  labs(title = 'Distribución de la Cantidad demandada de Helados Ben & Jerry', 
       subtitle = 'Unidades comparadas',
       x = '# Helados')
```
### 10. Grafica la $q(p)$. Que tipo de relación parecen tener? 

```{r sol10 }
ggplot(base, aes(price_unit, quantity))+
  geom_point()+
  geom_smooth()+
  theme_bw()+
  labs(title = 'Curva de demanda', 
       y = 'Cantidad Demandada (# Helados)', 
       x = 'Precio (USD)')

```
### 11. Grafica la misma relación pero ahora entre $log(p+1)$ y $log(q+1)$

```{r sol11 }
ggplot(base, aes(log(price_unit+1), log(quantity+1)))+
  geom_point()+
  geom_smooth()+
  geom_smooth(method = 'lm')+
  theme_bw()+
  labs(title = 'Curva de demanda', 
       subtitle = 'log',
       y = 'Cantidad Demandada (# Helados)', 
       x = 'Precio (USD)')

```
Usemos la transformación logarítmica a partir de este punto. Grafiquemos la demanda inversa. 

### 12. Grafica la curva de demanda por tamaño del helado. Parece haber diferencias en la elasticidad precio dependiendo de la presentación del helado? (2 pts)

La demanda por helados de mayor tamaño (32 OZ) parecen tener una demanda mas inelástica. 

```{r sol12 }
ggplot(base, aes(log(price_unit+1), log(quantity+1), color = size1_descr))+
  geom_point()+
  geom_smooth()+
  theme_bw()+
  labs(title = 'Curva de demanda', 
       y = 'Cantidad Demandada (# Helados)', 
       x = 'Precio (USD)', color = 'Tamaño')

```

### 13. Grafica la curva de demanda por sabor. Crea una variable con los 3 sabores más populares y agruga el resto de los sabores como 'otros'. Parece haber diferencias en la elasticidad precio dependiendo del sabor?

```{r sol13 }
# Detectando las top frequencies 
freq_sabores<-
  base %>% 
  group_by(flavor_descr) %>% 
  tally() %>% 
  arrange(desc(n))

base<-
  base %>%
  mutate(sabor = case_when(flavor_descr == freq_sabores$flavor_descr[1] ~ freq_sabores$flavor_descr[1],
                           flavor_descr == freq_sabores$flavor_descr[2] ~ freq_sabores$flavor_descr[2], 
                           flavor_descr == freq_sabores$flavor_descr[3] ~ freq_sabores$flavor_descr[3]), 
         sabor = replace_na(sabor, replace = 'Other'))

ggplot(base, aes(log(price_unit+1), log(quantity+1), color = sabor))+
  geom_point()+
  geom_smooth()+
  theme_bw()+
  labs(title = 'Curva de demanda', 
       y = 'Cantidad Demandada (# Helados)', 
       x = 'Precio (USD)', color = 'Tamaño')

```


## Estimación

### 14. Estima la regresión de la curva de demanda de los helados. Reporta la tabla de la regresión

Algunos tips: 

- No olvides borrar la variable que recien creamos de sabores. Incluirla (dado que es perfectamente colineal con flavor), sería una violación a supuesto GM 3 de la regresión. 

- No olvides quitar `quantity`, `price_unit`, `price_deal` y otras variables que sirven como identificadora. Tambien quitar `fips_state_code` y `fips_county_code`.

- Empecemos con una regresión que incluya a todas las variables. 


Nota: La regresión en `R` entiende que si le metes variables de texto, debe convertirlas a un factor. En algunos otros algoritmos que veremos durante el curso, tendremos que convertir manualmente toda la base a una númerica. 

Quitemos las fechas
```{r}
base$female_head_birth<-NULL
base$male_head_birth<-NULL
```

```{r sol14, results="asis"}
base<-
  base %>% 
  mutate(log_quantity = log(quantity+1), 
         log_price = log(price_unit+1))

base_estimacion<-
  base %>% 
  ungroup() %>%
  select(-c(quantity, price_paid_deal, price_paid_non_deal, price, price_unit, sabor, primary_key, fips_state_code))


var_na<-map_dbl(base_estimacion %>% select_all(), 
              ~100*sum(is.na(.))/nrow(base))

var_na<-var_na[var_na>0]


fit <- lm(log_quantity ~ ., data = base_estimacion %>% select(-household_id, -fips_county_code))

resultados<-tidy(fit)
kable(tidy(fit))

```


### 15 (2 pts). Cuales son los elementos que guarda el objecto de la regresión? Listalos. Cual es el F-test de la regresión? Escribe la prueba de manera matemática (i.e. como la vimos en clase). (Tip: `summary(fit)` te arroja algo del F-test)


$$H_0: \beta_i=0 \ \ H_a:Alguna \ \ \beta_i \neq 0$$

$$F = \frac{ESS(n-k-1)}{RSS(k)} =\frac{R^2(n-k-1)}{(1-R^2)k} = \frac{0.08847(21940-174-1)}{(1-0.08847)174} = 12.14$$
$$p(F)= 4.004x \ \ e^{-312}<0.01$$

Por lo tanto, la regresión explica más que el modelo nulo. 

```{r sol15}
a<-summary(fit)

a$fstatistic

pf(q = a$fstatistic[1], df1 = a$fstatistic[2], df2 = a$fstatistic[3], lower.tail = F)


```


### 16. Cuál es la elasticidad precio de los helados Ben and Jerry ? Es significativo? Interpreta el coeficiente 

$$\epsilon^Q_p= -0.1898^{***}$$
Esto se interpreta, si Ben and Jerry sube el precio de los helados 1 por ciento, la cantidad demandada caerá 0.1898 por ciento. Es un bien relativamente ineslástico. 


### 17. Cuántos p-values tenemos en la regresión. Haz un histograma de los p-values. 

```{r sol17 }

ggplot(resultados, aes(p.value))+
  geom_histogram(fill = 'lightsteelblue', color = 'darkgrey')+
  theme_bw()+
  labs(title = 'P-values modelo demanda Ben and Jerry', x = 'P-value')

```

### 18 (4pts). Realiza un ajuste FDR a una $q=0.10$. Grafica el procedimiento (con y sin zoom-in a p-values<0.05). Cuantas variables salían significativas con $\alpha = 0.05$? Cuantas salen con FDR? 
Tip: crea el ranking de cada p-value como `resultados %>% arrange(p.value) %>% mutate(ranking = row_number)`

Con la inferencia clásica ($\alpha=0.05$), salen 53 de 122 variables significativas. 

Con FDR a $q=0.1$, salen 45 variables significativas. 
```{r sol18}

# Cuantas salen con alpha 0.05

table(resultados$p.value<0.05)

# Creamos el ranking de los p-values 
resultados<-
  resultados %>%
  arrange(p.value) %>% 
  mutate(ranking = row_number())


resultados<-
  resultados %>% 
  mutate(corte_fdr = 0.1*ranking/nrow(resultados), 
         sig_fdr = if_else(p.value<=corte_fdr, 'Significativa', 'No significativa'))

table(resultados$sig_fdr)

# sin zoom -in
ggplot(resultados, aes(ranking, p.value, color = sig_fdr))+
  geom_point()+
  geom_line(aes(ranking, corte_fdr), color = 'black')+
  theme_bw()+
  theme(legend.position = 'bottom')+
  labs(title = 'FDR q=0.1', x = 'ranking', y = 'p value', color = 'Rech H0?')


# Con zoom -in
ggplot(resultados %>% filter(p.value<0.05), aes(ranking, p.value, color = sig_fdr))+
  geom_point()+
  geom_line(aes(ranking, corte_fdr), color = 'black')+
  theme_bw()+
  theme(legend.position = 'bottom')+
  labs(title = 'FDR q=0.1', x = 'ranking', y = 'p value', color = 'Rech H0?')


```


### 19 (2pts). Repite el ejercicio pero ahora con Holm-Bonferroni. Comparalo vs FDR. En este caso cuantas variables son significativas?  Haz la grafica comparativa (solo con zoom-in)

En este caso tambien hay 45 significativas. 

```{r sol19}
resultados <-
  resultados %>% 
  mutate(corte_hb = 0.05/(nrow(resultados) + 1 - ranking), 
          sig_hb = if_else(p.value<corte_fdr, 'Significativa', 'No Significativa'))


table(resultados$sig_hb)

resultados2<-
  resultados %>% 
  pivot_longer(cols = c(corte_fdr, corte_hb), names_to = 'metodo', values_to = 'corte')

# Con zoom -in
ggplot(resultados2 %>% filter(p.value<0.05), aes(ranking, p.value, color = sig_hb, shape = sig_fdr))+
  geom_point()+
  geom_line(aes(ranking, corte, color = metodo))+
  theme_bw()+
  theme(legend.position = 'bottom')+
  labs(title = 'FDR q=0.1 vs Holm Bonferroni', x = 'ranking', y = 'p value', color = 'Rech H0?')


```

